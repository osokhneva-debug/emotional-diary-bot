# analysis.py
import json
import csv
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Tuple, Optional
from collections import Counter, defaultdict
import io
import pytz

from db import get_session, User, Entry
from i18n import TEXTS, EMOTION_CATEGORIES

class EmotionAnalyzer:
    """Analyzes emotional data and generates insights"""
    
    def __init__(self):
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —ç–º–æ—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
        self.emotion_groups = {
            'recovery_growth': {
                'name': 'üå± –≠–º–æ—Ü–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–æ—Å—Ç–∞',
                'keywords': [
                    # –†–∞–¥–æ—Å—Ç—å/–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ
                    '—Ä–∞–¥–æ—Å—Ç—å', '—Å—á–∞—Å—Ç—å–µ', '–≤–æ—Å—Ç–æ—Ä–≥', '–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å', '–≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ', '–≥–æ—Ä–¥–æ—Å—Ç—å', '—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏–µ', '–±–ª–∞–∂–µ–Ω—Å—Ç–≤–æ',
                    # –ò–Ω—Ç–µ—Ä–µ—Å/–õ—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ  
                    '–∏–Ω—Ç–µ—Ä–µ—Å', '–ª—é–±–æ–ø—ã—Ç—Å—Ç–≤–æ', '—É–≤–ª–µ—á—ë–Ω–Ω–æ—Å—Ç—å', '–ø—Ä–µ–¥–≤–∫—É—à–µ–Ω–∏–µ', '–∞–∑–∞—Ä—Ç', '–∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å', '–ª—é–±–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
                    # –°–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ/–£–º–∏—Ä–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ
                    '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—Ä–∞—Å—Å–ª–∞–±–ª–µ–Ω–Ω–æ—Å—Ç—å', '–≥–∞—Ä–º–æ–Ω–∏—è', '–ø—Ä–∏–Ω—è—Ç–∏–µ', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '—É–º–∏—Ä–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ', '–±–µ–∑–º—è—Ç–µ–∂–Ω–æ—Å—Ç—å', '—Ä–∞–≤–Ω–æ–≤–µ—Å–∏–µ',
                    # –≠–Ω–µ—Ä–≥–∏—á–Ω–æ—Å—Ç—å/–í–æ–æ–¥—É—à–µ–≤–ª–µ–Ω–∏–µ
                    '–±–æ–¥—Ä–æ—Å—Ç—å', '—ç–Ω—Ç—É–∑–∏–∞–∑–º', '–≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ', '—Ä–µ—à–∏–º–æ—Å—Ç—å', '–¥—Ä–∞–π–≤', '–≤–æ–æ–¥—É—à–µ–≤–ª–µ–Ω–∏–µ', '–ø–æ–¥—ä—ë–º', '—ç–Ω–µ—Ä–≥–∏—è'
                ],
                'description': '–≠–º–æ—Ü–∏–∏, —Å–ø–æ—Å–æ–±—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–≤–∏—Ç–∏—é –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é'
            },
            'tension_signal': {
                'name': 'üå™ –≠–º–æ—Ü–∏–∏ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è –∏ —Å–∏–≥–Ω–∞–ª–∞',
                'keywords': [
                    # –¢—Ä–µ–≤–æ–≥–∞/–ë–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ
                    '—Ç—Ä–µ–≤–æ–≥–∞', '–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ', '–Ω–µ—Ä–≤–æ–∑–Ω–æ—Å—Ç—å', '—Å—Ç—Ä–∞—Ö', '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ', '—Å–æ–º–Ω–µ–Ω–∏–µ', '–≤–æ–ª–Ω–µ–Ω–∏–µ', '–æ–ø–∞—Å–µ–Ω–∏–µ',
                    # –ì—Ä—É—Å—Ç—å/–ü–µ—á–∞–ª—å
                    '–≥—Ä—É—Å—Ç—å', '–ø–µ—á–∞–ª—å', '—Ç–æ—Å–∫–∞', '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ', '–º–µ–ª–∞–Ω—Ö–æ–ª–∏—è', '–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ', '–≥–æ—Ä–µ', '—É–Ω—ã–Ω–∏–µ', '—Å–æ–∂–∞–ª–µ–Ω–∏–µ',
                    # –ó–ª–æ—Å—Ç—å/–†–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ
                    '–∑–ª–æ—Å—Ç—å', '—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ', '–≥–Ω–µ–≤', '–æ–±–∏–¥–∞', '—Ñ—Ä—É—Å—Ç—Ä–∞—Ü–∏—è', '–∑–∞–≤–∏—Å—Ç—å', '–≤–æ–∑–º—É—â–µ–Ω–∏–µ', '–Ω–µ–≥–æ–¥–æ–≤–∞–Ω–∏–µ',
                    # –°—Ç—ã–¥/–í–∏–Ω–∞
                    '—Å—Ç—ã–¥', '–≤–∏–Ω–∞', '—Å–º—É—â–µ–Ω–∏–µ', '–Ω–µ–ª–æ–≤–∫–æ—Å—Ç—å', '—Å–∞–º–æ–∫—Ä–∏—Ç–∏–∫–∞', '—É–≥—Ä—ã–∑–µ–Ω–∏—è', '—Ä–∞—Å–∫–∞—è–Ω–∏–µ',
                    # –£—Å—Ç–∞–ª–æ—Å—Ç—å/–ò—Å—Ç–æ—â–µ–Ω–∏–µ
                    '—É—Å—Ç–∞–ª–æ—Å—Ç—å', '–∏—Å—Ç–æ—â–µ–Ω–∏–µ', '–∞–ø–∞—Ç–∏—è', '–≤—ã–≥–æ—Ä–∞–Ω–∏–µ', '–±–µ–∑—Ä–∞–∑–ª–∏—á–∏–µ', '–≤—è–ª–æ—Å—Ç—å', '–∏–∑–Ω–µ–º–æ–∂–µ–Ω–∏–µ', '–æ–ø—É—Å—Ç–æ—à—ë–Ω–Ω–æ—Å—Ç—å',
                    # –£–¥–∏–≤–ª–µ–Ω–∏–µ/–®–æ–∫
                    '—É–¥–∏–≤–ª–µ–Ω–∏–µ', '–∏–∑—É–º–ª–µ–Ω–∏–µ', '–æ—à–µ–ª–æ–º–ª–µ–Ω–∏–µ', '—Ä–∞—Å—Ç–µ—Ä—è–Ω–Ω–æ—Å—Ç—å', '–Ω–µ–¥–æ—É–º–µ–Ω–∏–µ', '–ø–æ—Ç—Ä—è—Å–µ–Ω–∏–µ', '—à–æ–∫'
                ],
                'description': '–≠–º–æ—Ü–∏–∏, —Å–∏–≥–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–µ –æ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç—è—Ö –∏ –≤—ã–∑–æ–≤–∞—Ö'
            },
            'neutral': {
                'name': '‚öñ –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ/–ø—Ä–æ—á–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è',
                'keywords': [
                    '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ', '–æ–±—ã—á–Ω–æ', '–Ω–æ—Ä–º–∞–ª—å–Ω–æ', '–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å', '–Ω–µ—è—Å–Ω–æ—Å—Ç—å', '—Å–º–µ—à–∞–Ω–Ω–æ—Å—Ç—å'
                ],
                'description': '–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è'
            }
        }
    
    async def generate_summary(self, user_id: int, period: str) -> str:
        """Generate emotional summary for specified period"""
        try:
            # Parse period
            days = self._parse_period(period)
            if not days:
                return TEXTS['invalid_period']
            
            # Get entries for the period
            entries = self._get_entries_for_period(user_id, days)
            
            if not entries:
                return f"üì≠ –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π —ç–º–æ—Ü–∏–π.\n\n–ù–∞—á–Ω–∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —Å–≤–æ–∏ —ç–º–æ—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é /note!"
            
            # Generate comprehensive analysis
            summary_parts = []
            
            # Header
            period_name = {7: "–Ω–µ–¥–µ–ª—é", 14: "2 –Ω–µ–¥–µ–ª–∏", 30: "–º–µ—Å—è—Ü", 90: "3 –º–µ—Å—è—Ü–∞"}.get(days, f"{days} –¥–Ω–µ–π")
            summary_parts.append(f"üìä <b>–°–≤–æ–¥–∫–∞ –∑–∞ {period_name}</b>")
            summary_parts.append("")
            summary_parts.append("üìä <b>–¢–≤–æ—è –Ω–µ–¥–µ–ª—è –≤ —ç–º–æ—Ü–∏—è—Ö</b>")
            summary_parts.append("")
            
            # Emotion groups analysis
            group_analysis = self._analyze_emotion_groups(entries)
            emotion_details = self._get_emotion_details_by_group(entries)
            
            summary_parts.append("<b>üé≠ –≠–º–æ—Ü–∏–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º:</b>")
            summary_parts.append("")
            
            for group_key, group_data in self.emotion_groups.items():
                count = group_analysis.get(group_key, 0)
                group_name = group_data['name']
                
                summary_parts.append(f"<b>{group_name}:</b> {count} —Ä–∞–∑")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏ —ç–º–æ—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
                if count > 0 and group_key in emotion_details:
                    emotions_list = []
                    for emotion, freq in emotion_details[group_key].most_common(5):
                        emotions_list.append(f'"{emotion}" ({freq})')
                    if emotions_list:
                        summary_parts.append(", ".join(emotions_list))
                
                summary_parts.append("")
            
            # Trigger analysis by groups
            trigger_analysis = self._analyze_triggers_by_groups(entries)
            if trigger_analysis:
                summary_parts.append("<b>üîç –ß—Ç–æ –≤–ª–∏—è–ª–æ –Ω–∞ —ç–º–æ—Ü–∏–∏:</b>")
                summary_parts.append("")
                
                for group_key, triggers in trigger_analysis.items():
                    if triggers:
                        group_name = self.emotion_groups[group_key]['name']
                        # –°–æ–∫—Ä–∞—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤
                        if '–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–æ—Å—Ç–∞' in group_name:
                            trigger_title = "üå± –¢—Ä–∏–≥–≥–µ—Ä—ã –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —ç–º–æ—Ü–∏–π:"
                        elif '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è –∏ —Å–∏–≥–Ω–∞–ª–∞' in group_name:
                            trigger_title = "üå™ –¢—Ä–∏–≥–≥–µ—Ä—ã –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω—ã—Ö —ç–º–æ—Ü–∏–π:"
                        else:
                            trigger_title = "‚öñ –¢—Ä–∏–≥–≥–µ—Ä—ã –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö —ç–º–æ—Ü–∏–π:"
                        
                        summary_parts.append(f"<b>{trigger_title}</b>")
                        for trigger in triggers[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–ø-3
                            summary_parts.append(f"‚Ä¢ {trigger}")
                        summary_parts.append("")
            
            # Time patterns
            time_patterns = self._analyze_time_patterns(entries)
            if time_patterns:
                peak_hour = max(time_patterns.items(), key=lambda x: x[1])
                time_of_day = self._get_time_of_day_name(peak_hour[0])
                summary_parts.append(f"<b>‚è∞ –ü–∏–∫ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:</b> {peak_hour[0]}:00 ({time_of_day})")
            
            summary_parts.append(f"<b>üìà –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:</b> {len(entries)}")
            summary_parts.append("")
            
            # Footer
            summary_parts.append("<i>–•–æ—á–µ—à—å –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏? –ò—Å–ø–æ–ª—å–∑—É–π /export –¥–ª—è CSV-—Ñ–∞–π–ª–∞.</i>")
            
            return "\n".join(summary_parts)
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–≤–æ–¥–∫–∏: {str(e)}"
    
    def _analyze_emotion_groups(self, entries: List[Entry]) -> Dict[str, int]:
        """Analyze emotion distribution by groups using keyword matching"""
        group_counts = defaultdict(int)
        
        for entry in entries:
            if not entry.emotions:
                continue
                
            emotions = json.loads(entry.emotions) if isinstance(entry.emotions, str) else entry.emotions
            
            for emotion in emotions:
                emotion_lower = emotion.lower().strip()
                group_found = False
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É
                for group_key, group_data in self.emotion_groups.items():
                    keywords = group_data['keywords']
                    
                    # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
                    for keyword in keywords:
                        if (emotion_lower == keyword.lower() or 
                            keyword.lower() in emotion_lower or 
                            emotion_lower in keyword.lower()):
                            group_counts[group_key] += 1
                            group_found = True
                            break
                    
                    if group_found:
                        break
                
                # –ï—Å–ª–∏ —ç–º–æ—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∏ –≤ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø–µ, –æ—Ç–Ω–æ—Å–∏–º –∫ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º
                if not group_found:
                    group_counts['neutral'] += 1
        
        return dict(group_counts)
    
    def _get_emotion_details_by_group(self, entries: List[Entry]) -> Dict[str, Counter]:
        """Get detailed emotion counts for each group"""
        group_emotions = defaultdict(Counter)
        
        for entry in entries:
            if not entry.emotions:
                continue
                
            emotions = json.loads(entry.emotions) if isinstance(entry.emotions, str) else entry.emotions
            
            for emotion in emotions:
                emotion_lower = emotion.lower().strip()
                group_found = False
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É
                for group_key, group_data in self.emotion_groups.items():
                    keywords = group_data['keywords']
                    
                    # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
                    for keyword in keywords:
                        if (emotion_lower == keyword.lower() or 
                            keyword.lower() in emotion_lower or 
                            emotion_lower in keyword.lower()):
                            group_emotions[group_key][emotion] += 1
                            group_found = True
                            break
                    
                    if group_found:
                        break
                
                # –ï—Å–ª–∏ —ç–º–æ—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∏ –≤ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø–µ, –æ—Ç–Ω–æ—Å–∏–º –∫ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º
                if not group_found:
                    group_emotions['neutral'][emotion] += 1
        
        return dict(group_emotions)
    
    def _analyze_triggers_by_groups(self, entries: List[Entry]) -> Dict[str, List[str]]:
        """Analyze triggers grouped by emotion groups"""
        group_triggers = defaultdict(list)
        
        for entry in entries:
            if not entry.cause or not entry.emotions:
                continue
                
            emotions = json.loads(entry.emotions) if isinstance(entry.emotions, str) else entry.emotions
            cause = entry.cause.strip()
            
            if len(cause) < 3:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–∏—á–∏–Ω—ã
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫ –∫–∞–∫–æ–π –≥—Ä—É–ø–ø–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è —ç—Ç–∞ –∑–∞–ø–∏—Å—å
            emotion_group = None
            for emotion in emotions:
                emotion_lower = emotion.lower().strip()
                
                for group_key, group_data in self.emotion_groups.items():
                    keywords = group_data['keywords']
                    
                    for keyword in keywords:
                        if (emotion_lower == keyword.lower() or 
                            keyword.lower() in emotion_lower or 
                            emotion_lower in keyword.lower()):
                            emotion_group = group_key
                            break
                    
                    if emotion_group:
                        break
                
                if emotion_group:
                    break
            
            # –ï—Å–ª–∏ –≥—Ä—É–ø–ø–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –æ—Ç–Ω–æ—Å–∏–º –∫ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º
            if not emotion_group:
                emotion_group = 'neutral'
            
            group_triggers[emotion_group].append(cause)
        
        return dict(group_triggers)
    
    def _get_time_of_day_name(self, hour: int) -> str:
        """Get human-readable time of day name"""
        if 6 <= hour < 12:
            return "—É—Ç—Ä–æ–º"
        elif 12 <= hour < 17:
            return "–¥–Ω—ë–º"
        elif 17 <= hour < 22:
            return "–≤–µ—á–µ—Ä–æ–º"
        else:
            return "–Ω–æ—á—å—é"
    
    def _parse_period(self, period: str) -> Optional[int]:
        """Parse period string to number of days"""
        period_map = {
            "7": 7,
            "14": 14,
            "30": 30,
            "90": 90
        }
        return period_map.get(period)
    
    def _get_entries_for_period(self, user_id: int, days: int) -> List[Entry]:
        """Get entries for the specified period"""
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days)
        
        with get_session() as session:
            return session.query(Entry).filter(
                Entry.user_id == user_id,
                Entry.timestamp >= cutoff_date
            ).order_by(Entry.timestamp.desc()).all()
    
    def _get_emotion_frequency(self, entries: List[Entry]) -> Counter:
        """Get frequency of specific emotions"""
        emotion_counts = Counter()
        
        for entry in entries:
            if entry.emotions:
                emotions = json.loads(entry.emotions) if isinstance(entry.emotions, str) else entry.emotions
                for emotion in emotions:
                    emotion_counts[emotion] += 1
        
        return emotion_counts
    
    def _analyze_time_patterns(self, entries: List[Entry]) -> Dict[int, int]:
        """Analyze emotional activity by hour of day"""
        hour_counts = defaultdict(int)
        
        for entry in entries:
            hour = entry.timestamp.hour
            hour_counts[hour] += 1
        
        return dict(hour_counts)
    
    def generate_csv_export(self, entries: List[Entry]) -> io.BytesIO:
        """Generate CSV export of emotional data"""
        output = io.StringIO()
        
        fieldnames = [
            '–î–∞—Ç–∞', '–í—Ä–µ–º—è', '–≠–º–æ—Ü–∏–∏', '–ì—Ä—É–ø–ø–∞_—ç–º–æ—Ü–∏–π', '–ü—Ä–∏—á–∏–Ω–∞', '–ó–∞–º–µ—Ç–∫–∏'
        ]
        
        writer = csv.DictWriter(output, fieldnames=fieldnames)
        writer.writeheader()
        
        for entry in entries:
            emotions_str = ', '.join(json.loads(entry.emotions) if isinstance(entry.emotions, str) else entry.emotions) if entry.emotions else ''
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä—É–ø–ø—É —ç–º–æ—Ü–∏–π –¥–ª—è CSV
            emotion_group = "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ"
            if entry.emotions:
                emotions = json.loads(entry.emotions) if isinstance(entry.emotions, str) else entry.emotions
                for emotion in emotions:
                    emotion_lower = emotion.lower().strip()
                    
                    for group_key, group_data in self.emotion_groups.items():
                        keywords = group_data['keywords']
                        
                        for keyword in keywords:
                            if (emotion_lower == keyword.lower() or 
                                keyword.lower() in emotion_lower or 
                                emotion_lower in keyword.lower()):
                                if group_key == 'recovery_growth':
                                    emotion_group = "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ —Ä–æ—Å—Ç–∞"
                                elif group_key == 'tension_signal':
                                    emotion_group = "–ù–∞–ø—Ä—è–∂–µ–Ω–∏—è –∏ —Å–∏–≥–Ω–∞–ª–∞"
                                else:
                                    emotion_group = "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ"
                                break
                        
                        if emotion_group != "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ":
                            break
                    
                    if emotion_group != "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ":
                        break
            
            writer.writerow({
                '–î–∞—Ç–∞': entry.timestamp.strftime('%Y-%m-%d'),
                '–í—Ä–µ–º—è': entry.timestamp.strftime('%H:%M:%S'),
                '–≠–º–æ—Ü–∏–∏': emotions_str,
                '–ì—Ä—É–ø–ø–∞_—ç–º–æ—Ü–∏–π': emotion_group,
                '–ü—Ä–∏—á–∏–Ω–∞': entry.cause or '',
                '–ó–∞–º–µ—Ç–∫–∏': entry.notes or ''
            })
        
        # Convert to bytes
        output.seek(0)
        csv_bytes = io.BytesIO()
        csv_bytes.write(output.getvalue().encode('utf-8-sig'))  # UTF-8 with BOM for Excel
        csv_bytes.seek(0)
        
        return csv_bytes
